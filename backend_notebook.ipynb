{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BasicLingua Library for NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created By\n",
    "* [Fareed Khan](https://github.com/FareedKhan-dev)\n",
    "* [Asad Rizvi](https://github.com/Asad-94)\n",
    "\n",
    "\n",
    "GitHub Repository: [BasicLingua](https://github.com/FareedKhan-dev/basic_lingua)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\faree\\Desktop\\basiclingua\\.venv-basic-lingua\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Importing Module\n",
    "from basiclingua import BasicLingua\n",
    "client = BasicLingua(api_key=\"YOUR_GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['123-456-7890', '523-456-7892', 'fareed khan', 'asad rizvi', 'x123@gmail.com']\n"
     ]
    }
   ],
   "source": [
    "# Pattern Extraction\n",
    "\n",
    "user_input = '''The phone number of fareed khan and asad rizvi are 123-456-7890 and 523-456-7892. Please call for assistance and email me at x123@gmail.com'''\n",
    "patterns = '''email, phone number, name'''\n",
    "\n",
    "extracted_patterns = client.extract_patterns(user_input, patterns)\n",
    "\n",
    "print(extracted_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÌååÎ¶¨ÎìúÏπ∏Í≥º ÏïÑÏÇ¨Îìú Î¶¨Ï¶àÎπÑÏùò Ï†ÑÌôîÎ≤àÌò∏Îäî 123-456-7890Í≥º 523-456-7892ÏûÖÎãàÎã§. ÎèÑÏõÄÏù¥ ÌïÑÏöîÌïòÏãúÎ©¥ Ï†ÑÌôî Ï£ºÏãúÍ±∞ÎÇò x123@gmail.comÏúºÎ°ú Ïù¥Î©îÏùº Î≥¥ÎÇ¥ Ï£ºÏãúÍ∏∞ Î∞îÎûçÎãàÎã§.\n"
     ]
    }
   ],
   "source": [
    "# Text Translation\n",
    "\n",
    "user_input = '''The phone number of fareed khan and asad rizvi are 123-456-7890 and 523-456-7892. Please call for assistance and email me at x123@gmail.com'''\n",
    "target_lang = \"korean\"\n",
    "\n",
    "translated_text = client.text_translate(user_input, target_lang)\n",
    "\n",
    "print(translated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love mehran, but mehran is even better. Although, toyota is a class above all.\n"
     ]
    }
   ],
   "source": [
    "# Text Replacement\n",
    "\n",
    "user_input = '''I love Lamborghini, but Bugatti is even better. Although, Mercedes is a class above all.'''\n",
    "replacement_rules = '''all mentioned cars with mehran but mercerdes with toyota'''\n",
    "\n",
    "answer = client.text_replace(user_input, replacement_rules)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Lamborghini', 'cars'), ('Bugatti', 'cars'), ('Mercedes', 'cars'), ('Google', 'organization')]\n"
     ]
    }
   ],
   "source": [
    "# Named Entity Recognition\n",
    "\n",
    "user_input = '''I love Lamborghini, but Bugatti is even better. Although, Mercedes is a class above all. and I work in Google'''\n",
    "\n",
    "answer = client.detect_ner(user_input, ner_tags=\"cars, date, time\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The given text expresses a preference for Bugatti over Lamborghini, and Mercedes over both. It also mentions employment at Google. These preferences and the employment information constitute the main ideas of the text.\n"
     ]
    }
   ],
   "source": [
    "# Text Summarization\n",
    "\n",
    "user_input = '''I love Lamborghini, but Bugatti is even better. Although, Mercedes is a class above all. and I work in Google'''\n",
    "summary_length = 'medium' # short, medium, long\n",
    "\n",
    "summary = client.text_summarize(user_input, summary_length)\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15th October 2022\n"
     ]
    }
   ],
   "source": [
    "# Text Question Answering\n",
    "\n",
    "user_input = '''OpenAI has hosted a hackathon for developers to build AI models. The event took place on 15th October 2022. The event was a huge success with over 1000 participants from around the world.'''\n",
    "question = \"When did the event happen?\"\n",
    "\n",
    "answer = client.text_qna(user_input, question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Book Flight', 'Reserve Restaurant', 'Watch Football Match']\n"
     ]
    }
   ],
   "source": [
    "# Text Intent Detection\n",
    "\n",
    "user_input = '''let's book a flight for our vacation and reserve a table at a restaurant for dinner. also going to watch football match at 8 pm.'''\n",
    "intent = client.text_intent(user_input)\n",
    "print(intent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI host a hackathon for developer to build AI model. The event take place on 15th October 2022. The event be a huge success with over 1000 participant from around the world.\n"
     ]
    }
   ],
   "source": [
    "# Text Lemmatization/Stemming\n",
    "\n",
    "user_input = '''OpenAI has hosted a hackathon for developers to build AI models. The event took place on 15th October 2022. The event was a huge success with over 1000 participants from around the world.'''\n",
    "\n",
    "answer = client.text_lemstem(user_input, task_type=\"stemming\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OpenAI has hosted a hackathon for developers to build AI models', ' The event took place on 15th October 2022', ' The event was a huge success with over 1000 participants from around the world', '']\n"
     ]
    }
   ],
   "source": [
    "# Text Tokenization\n",
    "\n",
    "user_input = '''OpenAI has hosted a hackathon for developers to build AI models. The event took place on 15th October 2022. The event was a huge success with over 1000 participants from around the world.'''\n",
    "\n",
    "answer = client.text_tokenize(user_input, \".\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.04192694, -0.05051928, -0.034939777, 0.025280714, 0.012726914, 0.026818482, 0.068937935, 0.014136571, 0.08999535, -0.012914751]\n"
     ]
    }
   ],
   "source": [
    "# Text Embedding\n",
    "\n",
    "user_input = '''OpenAI has hosted a hackathon for developers to build AI models. The event took place on 15th October 2022. The event was a huge success with over 1000 participants from around the world.'''\n",
    "task_type = \"RETRIEVAL_QUERY\" # \"RETRIEVAL_QUERY\", \"RETRIEVAL_DOCUMENT\", \"SEMANTIC_SIMILARITY\", \"CLASSIFICATION\", \"CLUSTERING\"\n",
    "\n",
    "answer = client.text_embedd(user_input, task_type)\n",
    "print(answer[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the ethereal realm, a wolf on the prowl,\n",
      "Its gleaming eyes fixed on the celestial jewel,\n",
      "The moon, a shimmering beacon in the sky,\n",
      "A chase unfolds, a dance that fills the night.\n"
     ]
    }
   ],
   "source": [
    "# Text Generation\n",
    "\n",
    "user_input = '''Generate a poem of wolf chasing the moon.'''\n",
    "ans_length = 'short' # short, medium, long\n",
    "\n",
    "answer = client.text_generate(user_input, ans_length)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prediction': 'harmed'}\n"
     ]
    }
   ],
   "source": [
    "# Text Spam Detection\n",
    "\n",
    "user_input = '''Congratulations! You have won a lottery of $1,000,000!'''\n",
    "num_classes = \"harmed, not_harmed, unknown\"\n",
    "\n",
    "answer = client.detect_spam(user_input, num_classes, explanation=False)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>Heading</h1> para visit to this website https://www.google.com for more information about the product. and you can find the product at this address 1234\n"
     ]
    }
   ],
   "source": [
    "# Text Cleaning\n",
    "\n",
    "user_input = '''<h1>Heading</h1> <a>para</a> visit to this website https://www.google.com for more information about the product. and you can find the product at this address 1234'''\n",
    "clean_info = '''remove a tags but keep their inner text\n",
    "'''\n",
    "\n",
    "answer = client.text_clean(user_input, clean_info)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is a sample string to be transformed.\n"
     ]
    }
   ],
   "source": [
    "# Text Normalization\n",
    "\n",
    "user_input = \"This is a SAMPLE string to be transformed.\"\n",
    "mode = \"lowercase\"  # \"uppercase\" or \"lowercase\"\n",
    "\n",
    "transformed_string = client.text_normalize(user_input, mode)\n",
    "\n",
    "print(transformed_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we will order pizza and burgers at night\n"
     ]
    }
   ],
   "source": [
    "# Text Spellcheck\n",
    "\n",
    "user_input = '''we wlli oderr pzzia adn buregsr at nghti'''\n",
    "corrected_text = client.text_spellcheck(user_input)\n",
    "print(corrected_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Predicate': 'ate', 'Agent': 'John', 'Theme': 'the delicious pizza'}\n"
     ]
    }
   ],
   "source": [
    "user_input = '''John ate the delicious pizza with gusto.'''\n",
    "srl_result = client.text_srl(user_input)\n",
    "print(srl_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ['\"The company reported record profits for the third quarter.\"', '\"Profits soared in the third quarter, reaching unprecedented levels.\"'], 1: ['\"The latest fashion trends for spring and summer are unveiled.\"'], 2: ['\"Tips for improving productivity in the workplace.\"']}\n"
     ]
    }
   ],
   "source": [
    "# Text Clustering\n",
    "\n",
    "user_input = '''\n",
    "\"The company reported record profits for the third quarter.\", \"The latest fashion trends for spring and summer are unveiled.\",\n",
    "\"Profits soared in the third quarter, reaching unprecedented levels.\", \"Tips for improving productivity in the workplace.\"\n",
    "'''\n",
    "clusters = client.text_cluster(user_input)\n",
    "print(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prediction': 'very positive', 'explanation': 'The text expresses excitement and a positive feeling, indicating a very positive sentiment.'}\n"
     ]
    }
   ],
   "source": [
    "# Text Sentiment Analysis\n",
    "\n",
    "user_input = '''Congratulations! You have won a lottery of $1,000,000!'''\n",
    "num_classes = \"very positive, positive, neutral, negative, very negative\"\n",
    "\n",
    "answer = client.text_sentiment(user_input, num_classes, explanation=True)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prediction': 'horror', 'explanation': 'The text is about a ghost chasing the speaker in a dark forest, which is a common theme in horror stories. The speaker is also scared and running for their life, which adds to the sense of fear and suspense.'}\n"
     ]
    }
   ],
   "source": [
    "# Text Topic Classification\n",
    "\n",
    "user_input = '''a ghost is chasing me in the dark forest. I am scared and running for my life. I hope I can make it out alive.'''\n",
    "num_classes = \"story, horror, comedy\"\n",
    "\n",
    "answer = client.text_topic(user_input, num_classes, explanation=True)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'pronoun'),\n",
       " ('love', 'verb'),\n",
       " ('Lamborghini', 'noun'),\n",
       " (',', 'punctuation'),\n",
       " ('but', 'conjunction'),\n",
       " ('Bugatti', 'noun'),\n",
       " ('is', 'verb'),\n",
       " ('even', 'adverb'),\n",
       " ('better', 'adjective'),\n",
       " ('Although', 'conjunction'),\n",
       " ('Mercedes', 'noun'),\n",
       " ('is', 'verb'),\n",
       " ('a', 'determiner'),\n",
       " ('class', 'noun'),\n",
       " ('above', 'preposition'),\n",
       " ('all', 'pronoun')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text Part of Speech Tagging\n",
    "\n",
    "user_input = '''I love Lamborghini, but Bugatti is even better. Although, Mercedes is a class above all.'''\n",
    "\n",
    "answer = client.detect_pos(user_input)\n",
    "\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prediction': 'yes', 'explanation': 'The two sentences have the same meaning but use different sentence structures. Sentence 1 is in the active voice, while Sentence 2 is in the passive voice. The subject of Sentence 1 (Google) is the object of Sentence 2, and the object of Sentence 1 (the search engine) is the subject of Sentence 2.'}\n"
     ]
    }
   ],
   "source": [
    "# Text Paraphrasing\n",
    "\n",
    "user_input = [\"Google has updated their search engine.\", \"The search engine has been updated by Google.\"]\n",
    "\n",
    "answer = client.text_paraphrase(user_input, explanation=True)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " This is Fareed Hassan Khan's fee voucher.\n"
     ]
    }
   ],
   "source": [
    "# Text OCR\n",
    "\n",
    "image_path = \"image.jpg\"\n",
    "prompt = \"whose fees voucher is this?\"\n",
    "\n",
    "extracted_text = client.text_ocr(image_path, prompt)\n",
    "print(extracted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The sun gently rose above the horizon, painting the sky with hues of pink, orange, red etc. like rainbow.', 'Birds greeted the dawn with melodious songs, i.e. their chirping filling the air with a sense of serenity.', 'Dew glistened on the grass, sparkling like diamonds in the morning light.', 'A cool breeze whispered through the trees, carrying the scent of blooming flowers.']\n"
     ]
    }
   ],
   "source": [
    "# Text Segmentation\n",
    "\n",
    "user_input = '''The sun gently rose above the horizon, painting the sky with hues of pink, orange, red etc. like rainbow. Birds greeted the dawn with melodious songs, i.e. their chirping filling the air with a sense of serenity. Dew glistened on the grass, sparkling like diamonds in the morning light. A cool breeze whispered through the trees, carrying the scent of blooming flowers.'''\n",
    "\n",
    "sentences = client.text_segment(user_input, logical=True)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Laughing out loud, how can that be possible?\n"
     ]
    }
   ],
   "source": [
    "# Text Emotion Detection\n",
    "\n",
    "user_input = \"üòÇüòÇüòÇ how can that be possible?\"\n",
    "expanded_user_input = client.text_emojis(user_input)\n",
    "print(expanded_user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "# Text TF-IDF\n",
    "\n",
    "documents_list = [\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"The quick brown fox jumps over the lazy dog and the cat.\",\n",
    "    \"The quick brown fox jumps over the lazy dog and the cat in the park.\"\n",
    "]\n",
    "\n",
    "ngrams_size = 2  # Size of n-grams\n",
    "\n",
    "output_type = 'all'  # 'tfidf', 'ngrams', 'all'\n",
    "\n",
    "tfidf_matrix = client.text_tfidf(documents_list, ngrams_size, output_type)\n",
    "\n",
    "print(type(tfidf_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['be on the same page', 'throw in the towel']\n"
     ]
    }
   ],
   "source": [
    "# Text Idioms\n",
    "\n",
    "user_input = \"We need to be on the same page and not throw in the towel at the first sign of trouble.\"\n",
    "extracted_idioms = client.text_idioms(user_input)\n",
    "print(extracted_idioms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Word to Disambiguate: bat', 'Meaning1: The wooden implement used in baseball games (in the first sentence)', 'Meaning2: Nocturnal flying mammal (in the second sentence)']\n"
     ]
    }
   ],
   "source": [
    "# Text sense disambiguation\n",
    "\n",
    "user_input = '''The baseball player swung the bat with all his strength. A bat flew overhead as they walked through the woods at dusk.'''\n",
    "word_to_disambiguate = 'bat'\n",
    "\n",
    "meanings = client.text_sense_disambiguation(user_input, word_to_disambiguate)\n",
    "print(meanings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fox': 2, 'quick': 1, 'dog': 1}\n"
     ]
    }
   ],
   "source": [
    "# Text Word Frequency\n",
    "\n",
    "user_input = \"The quick brown fox jumps over the lazy dog and black fox.\"\n",
    "words = [\"fox\", \"quick\", \"dog\"]  # Specific words to calculate frequency for, or None for all words\n",
    "\n",
    "frequency = client.text_word_frequency(user_input, words)\n",
    "print(frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['singing bear']\n"
     ]
    }
   ],
   "source": [
    "# Text Anomaly Detection\n",
    "\n",
    "user_input = '''While hiking, I stumbled upon a cave filled with glowing mushrooms and a singing bear.'''\n",
    "anomalies = client.text_anomaly(user_input)\n",
    "print(anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['her: Emily', 'brother: James', 'they: Emily and James']\n"
     ]
    }
   ],
   "source": [
    "# Text Coreference Resolution\n",
    "\n",
    "user_input = '''Emily and her brother James decided to go on a camping trip together. Teams were formed and they set out to explore the forest.'''\n",
    "\n",
    "resolved_coreferences = client.text_coreference(user_input)\n",
    "print(resolved_coreferences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False <class 'bool'>\n"
     ]
    }
   ],
   "source": [
    "# Text Badness\n",
    "\n",
    "non_sarcastic_user_input = \"I love driving on empty roads with no traffic.\"\n",
    "\n",
    "analysis_type = \"sarcasm\"  # \"profanity\", \"bias\", \"sarcasm\"\n",
    "threshold = \"BLOCK_NONE\"  # \"BLOCK_NONE\", \"BLOCK_ONLY_HIGH\", \"BLOCK_MEDIUM_AND_ABOVE\", \"BLOCK_LOW_AND_ABOVE\"\n",
    "\n",
    "contains_language = client.text_badness(non_sarcastic_user_input, analysis_type, threshold)\n",
    "print(contains_language, type(contains_language))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-basic-lingua",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
